---
permalink: /
title: "Yuliang(Leo) Chen"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a first-year Data Science Master's student at UC San Diego. My research interests lie at the intersection of machine learning, computer vision, and natural language processing. I focus primarily on multi-sensor fusion for foundation models, language-driven representation learning, self-supervised learning, and physiological signal analysis.

You can find my CV here: [Yuliang Chen's Curriculum Vitae](../assets/Chen_Yuliang_DSCV.pdf).

[Email](mailto:yuc204@ucsd.edu) / [Github](https://github.com/yuc0805) / [LinkedIn](https://www.linkedin.com/in/yuliang-chen-74666b236/)


## Recent News
- [March 2024] Joined [MOSAIC Lab](https://mosaic.cs.umass.edu/) as a Research Assistant, collaborating with [Yunfei Luo](https://yunfeiluo.github.io/) under the advisement of [Professor Tauhidur Rahman](https://www.tauhidurrahman.com/)!
- [September 2023] Began the Data Science Master's program at UCSD!
- [October 2022] Started working as a Supply Chain Analyst at Micro Ingredients!
- [June 2022] Graduated from UCSB with a dual major in Mathematics and Statistics-Data Science!
  
## Projects
### Foundation Model on Physiological Signals
*Ongoing Project*  
Pioneered the application of self-supervised learning paradigms to develop foundational models for multi-variate
time-series data, enabling superior performance across a diverse array of downstream tasks, including prediction,
anomaly detection, and classification.
### [Vivid Panels: Deep Neural Networks for Manga Colorization](https://github.com/yuc0805/Manga-Colorization)
This study explores fine-tuning pre-trained GAN-based models for manga colorization, highlighting the performance gains achieved by addressing distribution differences between task-specific inputs and pre-training data.
### [VitT: Vision-Topological Transformer for Medical Image Classification](https://github.com/j8chiu/PH_ImageClassification/tree/ViT_Branch)
*Spring 2024*  
Introducing the VitT model, which incorporates task-specific topological features into a pre-trained ViT using a lightweight persistent diagram encoder and fusion layer, resulting in better performance than vanilla ViT linear probing with minimal computational cost.
### [E-StyTR^2: Efficient Image Style Transfer with Transformers](https://github.com/yuc0805/Image_Style_Transfer)
*Spring 2024*  
This project aims to optimize the StyTr2 framework for image style transfer, focusing on reducing computational demands while maintaining high performance. Additionally, the project investigates various fusion techniques to effectively blend style and content, evaluating their impact on the overall effectiveness and aesthetic quality of the transferred images using quantitative metrics.
### [Image-to-Image Retrieval with CLIP](https://github.com/yuc0805/Image-to-Image-Search-Using-CLIP)
*Winter 2024*  
In this project, I developed an image-to-image retrieval system using CLIP (Contrastive Language-Image Pretraining) to empirically show that CLIP can capture more robust and generalized image representations compared to traditional convolutional neural networks like ResNet.
### Navigating the Landscape of Explanation Multiplicity
*Fall 2023*  
This literature review examines the challenges and strategies associated with explanation multiplicity in machine learning models. The project aims to highlight the implications of having multiple explanations for model decisions and to develop effective methods for managing them.

